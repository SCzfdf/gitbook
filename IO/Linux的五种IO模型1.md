# Linux的五种IO模型1

[你管这破玩意叫 IO 多路复用？(简单易懂)](https://mp.weixin.qq.com/s/Ok7SIROXu1THUbWsFu-UYw)

[Unix/Linux 中的五种 I/O 模型(很多干货!!!)](https://jacktang816.github.io/post/iomodel/)

[IO 模型知多少 | 理论篇](https://www.cnblogs.com/sheng-jie/p/how-much-you-know-about-io-models.html)

[源码注释](https://github.com/kangjianwei/LearningJDK/find/master)

​		

五种IO模型分别为:

1.  **阻塞IO** (BIO)
2.  **非阻塞IO** (NIO)
3.  **IO多路复用**
4.  **信号驱动IO**
5.  **异步IO** (AIO)



阻塞IO, 非阻塞IO必看[你管这破玩意叫 IO 多路复用?](https://mp.weixin.qq.com/s/Ok7SIROXu1THUbWsFu-UYw) 里的动图. 很直观!(太大了不想拷贝过来)

## 阻塞IO

阻塞IO即是会阻塞的IO. 主要体现在

1.  **建立连接**时阻塞(`accept()`)
2.  **读取消息**时阻塞(`read()`)



其中`read()`的阻塞主要体现在2个方面

1.  数据从**网卡**到**内核缓冲区**会阻塞
2.  数据从**内核缓冲区**到**用户缓冲区**会阻塞



BIO伪代码: 

```java
channel = server.accept(); // 获取客户端连接时阻塞一次
msg = channel.read() // 读取数据时再阻塞一次
```

​		

整体流程如下: 

![BIO用户态和内核态](Linux%E7%9A%84%E4%BA%94%E7%A7%8DIO%E6%A8%A1%E5%9E%8B.assets/BIO%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81.svg)



### BIO优化

如果客户端一直不发数据那么服务端将不能接受新的连接. 这是不可接受的

因此对于BIO的优化主要在于`read()`的优化. 

可以在`accept()`返回时创建一个线程用于等待客户端发送消息

但这仅仅是用户层的小把戏. 对于多客户端的场景还是会有问题

>   比如连接太多会导致CPU不堪重负. 使用连接池的话如果池满了对新连接可能会丢失(看策略)

**因此还是需要恳请操作系统为我们提供一个非阻塞的`read()`**



## 非阻塞IO

非阻塞IO相对于阻塞IO来说. 

1.  解决了`accept()`的阻塞

2.  解决了`read()`中数据从网卡到内核缓冲区的阻塞

    >   `read()`解决了一半的阻塞



NIO伪代码:

```java
while((channel = server.accept()) != null) { // 因为非阻塞, 所以要循环判断
    new Thread(channel).start(); // 新建一个线程运行
}

// 线程run伪代码
while(channel.read(buffer) > -1) { // 如果还未拷贝到用户缓冲区则一直返回-1
    // 一些操作
}
```

​		

整体流程如下:

![NIO用户态和内核态](Linux%E7%9A%84%E4%BA%94%E7%A7%8DIO%E6%A8%A1%E5%9E%8B.assets/NIO%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81.svg)



### NIO优化

如果像伪代码一样为每个客户端都创建一个线程那么CPU很快会不堪重负.

因此可以将连接放到一个集合中遍历. 如果存在数据则进行操作

不过这也是存在问题的

>   比如因为是遍历并且是非阻塞因此一般情况下会把一个核心给占满. 同时`read()`是系统调用, 耗费资源巨大

**因此还是需要恳请操作系统帮我们将能操作的连接筛选出来**



## IO多路复用

多路复用存在三个函数

分别是`select()`, `poll()`, `epoll()`



### select

`select()`是操作系统提供的系统调用函数. 通过它可以将文件描述符数组发送给操作系统, 让系统去遍历. 如果存在可操作的文件描述符的数量.

![select动图](Linux%E7%9A%84%E4%BA%94%E7%A7%8DIO%E6%A8%A1%E5%9E%8B.assets/select%E5%8A%A8%E5%9B%BE.gif)

`select()`存在以下问题

1.  select函数最大只能支持1024个文件描述符
2.  需要用户将文件描述符数组拷贝到内核态, 在高并发状态下损耗是惊人的
3.  内核态使用的依旧是遍历检查的方式, 是一个同步的过程
4.  只返回可操作文件描述符数量, 用户仍需要遍历一次



### poll

`poll()`和`select()`的主要区别是`poll()`去掉了`select()`的文件描述符限制(解决了第一个问题)

​		

### epoll

针对`select()`的其余问题, `poll()`做了如下改进

2.  需要用户将文件描述符数组拷贝到内核态, 在高并发状态下损耗是惊人的

    >   内核中保存一份文件描述符集合, 无需用户每次都重新传入, 只需告诉内核修改的部分即可(**使用mmap**)

3.  内核态使用的依旧是遍历检查的方式, 是一个同步的过程

    >   内核不再通过轮询的方式找到就绪的文件描述符，而是通过异步 IO 事件唤醒(**不会因为监控文件的增多而导致性能下降**)

4.  只返回可操作文件描述符数量, 用户仍需要遍历一次

    >   `epoll()`仅会将就绪的文件描述符返回给用户. 用户无需遍历

![epoll动图](Linux%E7%9A%84%E4%BA%94%E7%A7%8DIO%E6%A8%A1%E5%9E%8B.assets/epoll%E5%8A%A8%E5%9B%BE.gif)





## 总结

>   一切的开始，都起源于这个 read 函数是操作系统提供的，而且是阻塞的，我们叫它 **阻塞 IO**。
>
>   为了破这个局，程序员在用户态通过多线程来防止主线程卡死。
>
>   后来操作系统发现这个需求比较大，于是在操作系统层面提供了非阻塞的 read 函数，这样程序员就可以在一个线程内完成多个文件描述符的读取，这就是 **非阻塞 IO**。
>
>   但多个文件描述符的读取就需要遍历，当高并发场景越来越多时，用户态遍历的文件描述符也越来越多，相当于在 while 循环里进行了越来越多的系统调用。
>
>   后来操作系统又发现这个场景需求量较大，于是又在操作系统层面提供了这样的遍历文件描述符的机制，这就是 **IO 多路复用**。
>
>   多路复用有三个函数，最开始是 select，然后又发明了 poll 解决了 select 文件描述符的限制，然后又发明了 epoll 解决 select 的三个不足。

**所以，IO 模型的演进，其实就是时代的变化，倒逼着操作系统将更多的功能加到自己的内核而已。**

​		

>   比如好多文章说，多路复用之所以效率高，是因为用一个线程就可以监控多个文件描述符。
>
>   这显然是知其然而不知其所以然，多路复用产生的效果，完全可以由用户态去遍历文件描述符并调用其非阻塞的 read 函数实现。而多路复用快的原因在于，操作系统提供了这样的系统调用，
>
>   **使得原来的 while 循环里多次系统调用，变成了一次系统调用 +  内核层遍历这些文件描述符。**
>
>   就好比我们平时写业务代码，把原来 while 循环里调 http 接口进行批量，改成了让对方提供一个批量添加的 http 接口，然后我们一次 rpc 请求就完成了批量添加。



​		

