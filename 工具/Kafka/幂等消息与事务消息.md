# 幂等消息与事务消息

[Kafka设计解析（三）恰好一次和事务消息](https://www.jianshu.com/p/f77ade3f41fd)

[Kafka幂等和事务](https://blog.csdn.net/oTengYue/article/details/104727512/)

​		

常见的消息交付可靠性保障有3种: 

1.   **最多一次**(at least once)

     消息可能会丢失, 但绝不会被重复发送

2.   **最少一次**(at most once)

     消息可能会重复, 但绝对不会丢失

3.   **精确一次**(exactly once)

     消息不会被丢失, 也不会重复发送

目前. kafka默认提供的可靠性保障为**最少一次**(at most once). 

实现是通过Producer的重试机制, 当网络抖动或者其他因素导致接受不到Broker返回的应答时, Producer就会选择重试

>   kafka也可以提供最多一次, 只要把重试禁用即可



## 使用幂等性Producer实现精确一次

[幂等性生产者](https://blog.csdn.net/alex_xfboy/article/details/82988259)

幂等性Producer使用ProducerId和SequenceNumber实现唯一性

*   **ProducerId(PID)**

    每个Producer初始化时分配. 用于标识本次会话

*   **SequenceNumber(Seq)**

    每个<PID, Topic, Partition>对应着一个从0开始递增的Seq值, 每发送一批消息+1.

Broker端也缓存了<PID, Topic, Partition>对应的Seq值. 对于收到的每条消息如果比缓存中的Seq大与1则正常接受, 否则将其丢弃, 这样就可以做到精确一次

但这个精确一次**只能保证单个Producer对于同一个<PID, Topic, Partition>的精确**

>   网上的代码很多都挺旧的...和我现在看的2.4不是一个版本. 粗略看了下差距感觉挺大的起码重新获取PID的代码不是阻塞的



### 使用幂等性Producer

原生kafka使用比较简单, 只需要在配置中加上

`props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)`即可



## 使用事务Producer实现全局精确一次

[kafka事务简介](https://www.jianshu.com/p/64c93065473e)

[Kafka设计解析（三）恰好一次和事务消息](https://www.jianshu.com/p/f77ade3f41fd)

kafka中的事务主要有两功能: 

1.   实现原子写(Producer的精确一次)
2.   拒绝僵尸实例

>   有博客将读事务消息也写进去了, 感觉这不像功能啊... 是事务的一部分

​		

事务的核心代码在`org.apache.kafka.clients.producer.internals.Sender#runOnce`中. 本来还想逐句解析的, 没找到博客印证又怕写错= =

所以这里只写响应流程

1.   **查找Coordinator**

     Producer发送一个`FindCoordinatorRequest`请求到任意Broker获取**Transaction Coordinator(事务协调器)**地址

2.   **初始化事务**

     Producer发送一个`InitpidRequest`请求到**Transaction Coordinate**获取**PID**

     1.   如果检测到之前Producer中存在事务则会尝试完成它(commit/abort)
     2.   对PID对应的epoch递增

3.   **启动事务**

     Producer执行`beginTransacion()`作用是在本地记录下这个Transaction的状态为开始状态

     这个不会和**Transaction Coordinate**发生交互

4.   **写消息**

     1.   Producer正常发送消息. **Transaction Coordinate**会将消息记录在**Transaction Log**中, 并将事务状态改为**BEGIN**. 
     2.   此外如果是事务的第一条消息Coordinate还会开启计时(事务有超时时间)

     >   此时的消息已经保存在Broker中了, 后续的commit/abort请求都只会修改消息的状态

5.   **提交/回滚事务**

     Producer向**Transaction Coordinate**发送`commitTransaction`或`abortTransaction`请求

     1.   Coordinate会将**Transaction Log**内的事务状态设置为`PREPARE_COMMIT`或`PREPARE_ABORT`
     2.   将**Transaction Marker**写入该事务涉及到的所有消息, 并分发给对应Partition
     3.   等待Partition写入完成后Coordinate会将**Transaction Log**内的事务状态设置为`COMPLETE_ABORT`标记一个事务的结束

<br/>

### 原生Kafka使用事务Producer

1.   Producer设置

     1.   开启幂等性生产者

          `props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)`

     2.   设置事务Id

          `props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "tx-");`

2.   Consumer设置

     设置读提交

     `props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, "read_committed");`

     >   默认是`read_uncommitted`表示无论是否已提交的事务都可以读到

示例: 

```java
producer.initTransactions();
try { 
    producer.beginTransaction(); 
    producer.send(record1); 
    producer.send(record2); 
    producer.commitTransaction();
} catch (KafkaException e) {
    producer.abortTransaction();
}
```





### Spring-kafka使用事务Producer

[spring-kafka开启事务](https://www.cnblogs.com/yanliang12138/p/12554756.html)

[springboot2.x +kafka使用](https://blog.csdn.net/F_Hello_World/article/details/103347403)

**使用全局事务:**

```java
@Bean
public ProducerFactory<Integer, String> producerFactory() {
    DefaultKafkaProducerFactory factory = new DefaultKafkaProducerFactory<>(senderProps());
    // 开启事务并设置事务前缀, 相当于是原生的开始幂等和设置事务id
    factory.transactionCapable();
    factory.setTransactionIdPrefix("tx-");
    return factory;
}

@Bean
public KafkaTransactionManager transactionManager(ProducerFactory producerFactory) {
    // 感觉应该不用手动注入才对...不应该自动注入了么...
    return new KafkaTransactionManager(producerFactory);
}
```

注入后`KafkaTemplate`自动开启事务, 之后使用`KafkaTemplate`必须要附带`@Transactional`或开启本地事务

>   注入多个KafkaTemplate不需要事务的就不加? 

​		

**使用本地事务**

```java
kafkaTemplate.executeInTransaction(new KafkaOperations.OperationsCallback() {
    @Override
    public Object doInOperations(KafkaOperations kafkaOperations) {
        kafkaOperations.send("topic.quick.tran", "test executeInTransaction");
        throw new RuntimeException("fail");
        return true;
    }
});
```

本地事务不支持事务嵌套, 只能把逻辑都丢到`executeInTransaction()`里执行

​		

还有一种本地事务是直接使用注解

```java
@Transactional(transactionManager = "kafkaTransactionManager")
public void kafkaTransactional(){
    // 多个send...
}
// 感觉应该不太行, kafkaTemplate.inTransaction()应该会返回false吧. 
// 毕竟producerFactory都没有开启事务
```



