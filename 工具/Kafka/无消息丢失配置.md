# kafka无消息丢失配置

**Broker端**

1.   **unclean.leader.election.enable = false** 

     禁止ISR外的副本成为Leader. => 落后太多的Broker成为Leader必然会造成消息丢失

2.   **replication.factor >= 3**

     指定副本数. 这里想表述的是最好将消息多保存几份

3.   **min.insync.replicas > 1**

     消息最少写入几个副本才算已提交

     >   如果ack=all, 且ISR同步副本是10个, min.insync.replicas=5
     >
     >   那么broker还是需要同步给其他10个副本才会返回成功，这个min.insync.replicas=5代表的是，整个ISR同步副本至少要有5个，不然producer就会报错。

4.   **replication.factor > min.insync.replicas**

     如果两者相等那么只要有一个副本挂机, 整个分区就无法正常工作了. 

​		

**Producer端**

1.   **acks = all**

     声明所有ISR的副本都收到消息才算已提交

2.   **retries >= 3**

     指定重试次数. 

3.   **使用带回调的send方法**

     `producer.send(msg, callback)`. 不带回调的话错误了也是无感知的

​		

**Consumer端**

1.   **enable.auto.commit = false**

     关闭自动提交. 采用手动提交位移的方式

     这倒是比较难控制的, 单线程还好. 但是单Consumer多线程的消费方式代码实现异常困难. 因为很难正确的更新位移. 

     也就是说避免无消费消息丢失很简单, 但极易出现消息被消费了多次的情况

​		

