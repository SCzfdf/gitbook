# kafka分区和副本



## 分区

为了实现**横向扩展**, 把不同数据存放在不同Broker上, 同时减轻单台服务器的访问压力. 

Kafka将Topic的数据分割成多个Partition

**单个Partition的消息是有序的**, 顺序读写. 但全局无序

>   不同分区能够放置在不同节点的机器上. 而对消息的读写也是针对分区这个粒度进行的. 这样每个节点的机器都能独立执行各自分区的读写请求. 并且还能通过增加机器来增加整体的吞吐量
>
>   这也是很多分布式系统对分区的底层思想

在服务器上, 每个Partition都对应一个物理目录. Topic名称后面的数字即代表分区编号

![image-20210828153023073](%E5%88%86%E5%8C%BA%E5%92%8C%E5%89%AF%E6%9C%AC.assets/image-20210828153023073.png)

​		

​		

## 副本

为了**提高分区可靠性**, Kafka引入了副本机制. (提供数据冗余和高可用. 新版本副本还会提供**有限度的**读功能)

>   副本数必须 小于等于 节点数. => 确保不会有一个分区的副本在同一台机器上存在2份

Kafka的副本分为2种角色

*   leader

    对外提供读写功能

*   follower

    异步从leader中拉取数据(备份)

>   [Kafka为什么没有选择支持读写分离(从follower读数据)](https://www.zhihu.com/question/327925275)
>
>   1.   Kafka是一个消息引擎, 有频繁的消息写入操作. 不是经典的读多写少
>   2.   设计天然支持对外负载均衡(分区+segment)
>   3.   引入读写分离会引发很多额外情况. (主从同步的延时问题, 数据一致性问题, offset维护问题)
>   4.   为了实现**Read-your-writes**(看到最新写入的消息)和**单调读**(消息不会一会存在一会不存在)



​		

## leader和follower分布策略

1.   副本不能大于Broker数
2.   第一个分区的第一个副本(leader)位置随机从BrokerList选取(图片是中间Broker)
3.   其他分区的第一个副本往后顺延
4.   剩余副本随机分布

下图为4分区2副本的分区

![kafka分区生成规则](%E5%88%86%E5%8C%BA%E5%92%8C%E5%89%AF%E6%9C%AC.assets/kafka%E5%88%86%E5%8C%BA%E7%94%9F%E6%88%90%E8%A7%84%E5%88%99.svg)





## Kafka分区策略

[Kafka Producer Sticky Partitioner](https://www.cnblogs.com/huxi2b/p/12540092.html)

所谓分区策略就是决定生产者将的消息会被分配到哪个分区的算法

kafka的默认分区策略为`org.apache.kafka.clients.producer.internals.DefaultPartitioner`

该策略默认使用`StickyPartition`(粘性分区 2.4后支持)

1.   当key存在时

     使用key的hash值 % 分区数 获取分区编号

2.   当key不存在时

     使用随机数 % 分区数 获取分区编号, 并且后续key不存在的消息**都会发给该分区**(topic相同且分区数没发生改变)

>   [!notice]
>
>   这只是`StickyPartition`算法的策略. 
>
>   在调用之前还要判断是否手动**指定partition**和是否手动**指定分区器**(存在则优先使用)

一旦分区的batch已满或者处于已完成状态. `StickyPartition`会重新选择另一分区, 并**坚持使用直到新分区的batch已满或者已完成**		

>   2.4版本之前默认分区策略为轮询, 该策略能够很好的负载分区消息, 但会构建大量的小batch从而提高消息发送成本. 并且拉长时间线来看. 粘性分区也有很好的负载功能



## 自定义分区策略

实现`org.apache.kafka.clients.producer.Partitioner`接口(接口很简单)

并且在product中注册

`properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, DefaultPartitioner.class.getName())`

在Spring中并没有暴露相关配置项, 但可以使用注入bean的方式注入配置

```java
@Bean
public ProducerFactory<Integer, String> producerFactory() {
    return new DefaultKafkaProducerFactory(producerProperties());
}

@Bean
public Map<String, Object> producerProperties() {
    Map<String, Object> props = new HashMap<String, Object>();
    // props 保存kafka原生配置
    
    return props;
}
```

