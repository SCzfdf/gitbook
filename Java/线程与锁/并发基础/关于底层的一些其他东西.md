# 关于底层的一些其他东西

>   事实上，我很多次以为我懂了volatile的原理，最终都是错误的。

[volatile和内存屏障](https://blog.lovezhy.cc/2020/03/08/volatile%E5%92%8C%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/)

[高并发编程--多处理器编程中的一致性问题](https://zhuanlan.zhihu.com/p/48157076)

[一次深入骨髓的 volatile 研究(超详细)](https://zhuanlan.zhihu.com/p/144712930)

百度谷歌上的大部分文章包括并发编程艺术上的对于内存屏障说的都不太清晰, 本想着找一些关于内存屏障的资料, 没想到发现了这个干货博客

面试用不上, 但对了解底层并发, 构建完整的知识系统还是有一定帮助

---

​		

## 强弱内存模型

[强弱内存模型](https://cch123.gitbooks.io/duplicate/content/part3/multithreading/strong-and-weak-memory-models.html)

[深入探索并发编程系列(九)-弱/强内存模型](https://chonghw.github.io/blog/2016/10/30/memorymodel/)

内存模型可以分为四大类, 从宽松到最强约束分别为:

*   完全弱一致

    在不影响单线程执行的情况下处理器可以进行任意重排序

*   数据依赖顺序弱一致

    如果数据之间不存在依赖的情况下处理器可以进行任意重排序

    >   如在 load 之间的依赖。比如我们从内存中取一个地址的值，然后用这个值再进行一次取值

*   通常强一致

    所有的store操作和程序编写的顺序是一致的, 但一些load操作可能会被重排序

*   线性一致

    不会发生任何重排序
    
    ​	

---

​		

## CPU流水线

[处理器中的流水线技术](https://zhuanlan.zhihu.com/p/109574885)

CPU执行一条指令可以分为几个过程(架构不同过程也不同), 这里简单的用3个步骤表示:

1.  取址

    从内存中取出指令

2.  执行

    处理器执行运算

3.  回写

    将结果写回寄存器或者缓存
    
    ​	

如果无流水线结构一个指令需要3个处理器周期来完成

![无CPU流水线](%E5%85%B3%E4%BA%8E%E5%BA%95%E5%B1%82%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%B6%E4%BB%96%E4%B8%9C%E8%A5%BF.assets/%E6%97%A0CPU%E6%B5%81%E6%B0%B4%E7%BA%BF.png)

如果引入CPU流水线则耗时大大减少

![CPU流水线](%E5%85%B3%E4%BA%8E%E5%BA%95%E5%B1%82%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%B6%E4%BB%96%E4%B8%9C%E8%A5%BF.assets/CPU%E6%B5%81%E6%B0%B4%E7%BA%BF.png)

>   看了几篇博客也还是不知道为什么CPU流水线会比无流水线快, 只模糊的知道使用流水线技术的话在一个指令完成了第一个步骤之后后续步骤就可以和其他指令并行执行

在上面CPU流水线的图中流水线执行是完美的. 但那只是三个指令没有数据依赖的关系, 如果指令3依赖指令1和2, 那么就会和预期结果不符(指令2还没执行完毕, 值还没写回寄存器)

​		

---

为了解决这个问题有两种方法解决

1.  执行空泡指令

    万能解决方案, 使处理器空转一个周期

2.  **指令重排(这就是指令级的并行重排序)**

    将有数据依赖的指令后置, 在期间插入无依赖的指令达到消除停顿的目的
    
    ​	

---

​		

## 顺序一致性内存模型

顺序一致性内存模型(Sequence Consistency)的特征:

**线程中的执行顺序必须按照程序的编写顺序执行**

>   并发编程艺术中还有一个特征: 每个操作都必须为原子执行, 且立刻对所有线程可见. 所有线程都只能看到一个单一的操作执行顺序. 

从上面的强弱内存分类来看, 顺序一致性内存模型是约束最强的线性一致模型

也就是说以下代码的执行结果`a == 1`必定是成立的

```java
int a; boolean b;
public void write(){
    a = 1;
    b = true
}
public void read(){
    while (!b) continue;
    assert(a == 1);
}
```

​		

---

​		

## 处理器内存模型

SC严格定义了对共享内存的操作, LoadLoad, LoadStore, StoreLoad, StoreStore是不允许重排序的. 但CPU的处理速度依旧远超内存好几个级别了, 如果严格按照SC则会使CPU的处理速度下降到和内存一样. 这是不能忍受的

因此现在找不到完全遵循SC的处理器. 

*   在顺序一致内存模型的基础上放松 写-读操作. 产生了Total Store Ordering(TSO)
*   在TSO的基础上继续放松 写-写操作. 产生了 Partial Store Order(PSO)
*   在上述基础上再放松 读-写和读-读操作. 产生了Relaxed Memory Order(RMO)和PowerPC

![处理器内存模型特征表](%E5%85%B3%E4%BA%8E%E5%BA%95%E5%B1%82%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%B6%E4%BB%96%E4%B8%9C%E8%A5%BF.assets/image-20201203085154654.png)

![处理器的重排序规则](%E5%85%B3%E4%BA%8E%E5%BA%95%E5%B1%82%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%B6%E4%BB%96%E4%B8%9C%E8%A5%BF.assets/%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E9%87%8D%E6%8E%92%E5%BA%8F%E8%A7%84%E5%88%99.png)

>   **x86和SPARC-TSO架构下的处理器只允许对StoreLoad进行重排序, 所以在这2个强一致性架构下的内存可见性问题基本都不是指令重排导致的**

​			

Total Store Order(TSO) X86架构CPU对于SC的一个优化实现.

**在CPU和内存之间引入write buffer(也就是之前的Store Buffer, 但没有invalidate queue)**. 将CPU和内存之间的差距隐藏起来的

​			

---

因为引入了write buffer. 所以TSO架构**不保证StoreLoad**的顺序

CPU0执行了`far()` 

CPU1执行了`bar()`

因为CPU执行write操作时只是将值送入了write buffer, 所以x, y的值可能是0或1

```java
int x = 0, y = 0;
int a = 0, b = 0;
void far() {
    a=1;
    x=b;
}
void bar() {
    b=1;
    y=a;
}
```

在X86等强一致性内存架构下, 造成x, y的值不确定的原因是write buffer导致的内存可见性问题, 而不是CPU的指令重排

​		

---

​		

## 硬件层面的内存屏障

[Volatile：内存屏障原理应该没有比这篇文章讲的更清楚了](https://zhuanlan.zhihu.com/p/208788426)

内存屏障称为fence

针对TSO等非线性一致架构下CPU可能出现的可见性问题提出的一种解决方案. 作用就是将缓冲区的内容写回内存/将失效队列里的消息生效

x86/64架构下提供了三种多核的内存屏障指令:

1.  sfence 写屏障: 该指令前的写操作必须在该指令后的写操作前完成

2.  lfence 读屏障

3.  mfence 读写屏障/全屏障

---

​		

## JMM内存屏障

[volatile底层原理详解](https://blog.csdn.net/lpf463061655/article/details/105645782)

[为什么在 x86 架构下只有 StoreLoad 屏障是有效指令？](https://zhuanlan.zhihu.com/p/81555436)

因为Java是跨平台语言, 不能直接使用某一硬件架构下的内存屏障, 所以在抽象的JMM上定义了4个抽象的内存屏障. 这4个内存屏障通过类似策略模式的方法在不同硬件架构下使用不同的实现保证了JMM的内存语义(英文好的同学真的强烈建议阅读JVM源码`runtime\orderAccess.hpp`)

分别是:

*   LoadLoad

    Load1；LoadLoad：Load2

    确保Load1 在Load2(及其后的指令) 之前的指令前完成.  

*   LoadStore

*   StoreStore

*   StoreLoad

---

例如在linux X86(`hotspot\src\os_cpu\linux_x86\vm\orderAccess_linux_x86.inline.hpp`)下:

可以看到LoadLoad的实现是通过汇编指令`movq`来实现的. StoreLoad是通过`lock`指令实现的

```c++
inline void OrderAccess::loadload()   { acquire(); }
inline void OrderAccess::storestore() { release(); }
inline void OrderAccess::loadstore()  { acquire(); }
inline void OrderAccess::storeload()  { fence(); }

inline void OrderAccess::acquire() {
  volatile intptr_t local_dummy;
#ifdef AMD64
  __asm__ volatile ("movq 0(%%rsp), %0" : "=r" (local_dummy) : : "memory");
#else
  __asm__ volatile ("movl 0(%%esp),%0" : "=r" (local_dummy) : : "memory");
#endif // AMD64
}

inline void OrderAccess::release() {
  // Avoid hitting the same cache-line from
  // different threads.
  volatile jint local_dummy = 0;
}

inline void OrderAccess::fence() {
  if (os::is_MP()) {
    // always use locked addl since mfence is sometimes expensive
#ifdef AMD64
    __asm__ volatile ("lock; addl $0,0(%%rsp)" : : : "cc", "memory");
#else
    __asm__ volatile ("lock; addl $0,0(%%esp)" : : : "cc", "memory");
#endif
  }
}
```

>   为什么不用mfence. 
>
>   always use locked addl since mfence is sometimes expensive
>
>   为什么选用lock
>
>   ```txt
>   All usable chips support "locked" instructions which suffice
>   as barriers, and are much faster than the alternative of
>   using cpuid instruction. We use here a locked add [esp],0.
>   This is conveniently otherwise a no-op except for blowing
>   flags.
>   Any change to this code may need to revisit other places in
>   the code where this idiom is used, in particular the
>   orderAccess code.
>   ```

​		

---

​		

## LOCK

[聊聊CPU的LOCK指令](https://albk.tech/%E8%81%8A%E8%81%8ACPU%E7%9A%84LOCK%E6%8C%87%E4%BB%A4.html)

`("lock; addl $0,0(%%esp)" : : : "cc", "memory")`

ddl $0,0(%%rsp) 的作用: 把寄存器的值加0. 相当于一个空操作. 之所以不用空操作专用的nop指令是因为x86指令集不支持lock nop



**lock指令的作用**: 锁住操作的共享内存(缓存行), 使接下来的指令变为原子指令. 并将当前处理的缓存行刷新到内存中并使其他处理器对应的缓存失效. 该写入操作会引起其他处理器对应的缓存失效

>   lock指令应该就是之前所说的总线锁定/缓存锁定的实现

>   同时也没有博客提到了mfence有禁止指令重排的功能(可能是我没找到?), 所以要实现volatile在JMM上定义的内存语义只能使用LOCK

~~但同样在我能找到的博客里对LOCK指令的描述也没有说他能把buffer中的数据刷新到内存. 它的作用只是通过锁定总线/缓存把后续指令变成一个原子操作. 顶多也是把要执行操作的变量所在的缓存行在其他处理器中失效, 并且会回写它锁住的缓存行. 但没有说会提交buffer的数据~~

~~但没有提交buffer的话volatile的内存语义就不能实现...所以有2个猜测.~~ 

1.  ~~在使用LOCK指令时会把操作变量所在的CPU缓存行都设置为失效. 再从内存中获取(此时是独占状态). 操作完后再把buffer中的数据提交(博客)~~
2.  ~~LOCK指令会吧变量所在的缓存行锁定(其他CPU不能操作), 修改完之后提交buffer(并发编程艺术)~~

在并发编程的艺术`3.5.3锁的内存语义的实现` 下找到了LOCK前缀的说明. 说明如下:

1.  使用总线锁/缓存锁确保后续指令的原子性
2.  禁用该指令与之前之后的指令重排
3.  把写缓冲区的数据刷新到内存中

    ​	

---

​		

## 对于写的猜想

StoreBuffer是CPU对于写的优化. 

但是如果加了LOCK指令应该不会走StoreBuffer, 而是由CPU直接发起总线/缓存锁. 

并在之前或之后, 把StoreBuffer的内容刷新到内存

​		

为什么要把StoreBuffer提交到内存? 

对于强一致性架构来说. 因为要保持StoreStore, 不能对只LOCK住的变量(volatile)写生效了, 它上一个写操作还没生效.

对于弱一致性架构的话则应该不会主动提交. 但java语言会对volatile变量加内存屏障达到相同的效果













